{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred while fetching page 30: 404 Client Error: Not Found for url: https://www.trustpilot.com/review/morenutrition.de?page=30\n",
      "Error occurred while fetching page 31: 404 Client Error: Not Found for url: https://www.trustpilot.com/review/morenutrition.de?page=31\n",
      "Error occurred while fetching page 32: 404 Client Error: Not Found for url: https://www.trustpilot.com/review/morenutrition.de?page=32\n",
      "Error occurred while fetching page 33: 404 Client Error: Not Found for url: https://www.trustpilot.com/review/morenutrition.de?page=33\n",
      "Error occurred while fetching page 34: 404 Client Error: Not Found for url: https://www.trustpilot.com/review/morenutrition.de?page=34\n",
      "Error occurred while fetching page 35: 404 Client Error: Not Found for url: https://www.trustpilot.com/review/morenutrition.de?page=35\n"
     ]
    }
   ],
   "source": [
    "from time import sleep\n",
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def soup2list(src, list_, attr=None):\n",
    "    if attr:\n",
    "        for val in src:\n",
    "            list_.append(val[attr])\n",
    "    else:\n",
    "        for val in src:\n",
    "            list_.append(val.get_text())\n",
    "\n",
    "users = []\n",
    "userReviewNum = []\n",
    "ratings = []\n",
    "locations = []\n",
    "dates = []\n",
    "reviews = []\n",
    "\n",
    "\n",
    "start_page = 1\n",
    "end_page = 35\n",
    "# Add the company name to pull from\n",
    "company = \"morenutrition.de\"\n",
    "\n",
    "for i in range(start_page, end_page + 1):\n",
    "    try:\n",
    "        result = requests.get(f\"https://www.trustpilot.com/review/{company}?page={i}\")\n",
    "        result.raise_for_status()  # Raise an error for bad responses\n",
    "        soup = BeautifulSoup(result.content, 'html.parser')\n",
    "\n",
    "        # Get the company name to put into the dataset\n",
    "        parts = company.split('.')\n",
    "        if parts[0] == 'www':\n",
    "            companyName = parts[1]\n",
    "        else:\n",
    "            companyName = parts[0]\n",
    "\n",
    "        soup2list(soup.find_all('span', {'class': 'typography_heading-xxs__QKBS8 typography_appearance-default__AAY17'}), users)\n",
    "        soup2list(soup.find_all('div', {'class': 'typography_body-m__xgxZ_ typography_appearance-subtle__8_H2l styles_detailsIcon__Fo_ua'}), locations)\n",
    "        soup2list(soup.find_all('div', {'class': 'styles_reviewHeader__iU9Px'}), dates)\n",
    "        soup2list(soup.find_all('div', {'class': 'styles_reviewHeader__iU9Px'}), ratings, attr='data-service-review-rating')\n",
    "        soup2list(soup.find_all('div', {'class': 'styles_reviewContent__0Q2Tg'}), reviews)\n",
    "\n",
    "        sleep(1)\n",
    "\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Error occurred while fetching page {i}: {e}\")\n",
    "        \n",
    "review_data = pd.DataFrame(\n",
    "    {\n",
    "        'Username': users,\n",
    "        'Location': locations,\n",
    "        'Date': dates,\n",
    "        'Rating': ratings,\n",
    "        'Company': companyName,\n",
    "        'Review': reviews\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Username</th>\n",
       "      <th>Location</th>\n",
       "      <th>Date</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Company</th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Der auf die Bestellung wartet...</td>\n",
       "      <td>DE</td>\n",
       "      <td>Apr 21, 2024</td>\n",
       "      <td>3</td>\n",
       "      <td>morenutrition</td>\n",
       "      <td>Wolf of WallstreetProdukte teilweise sehr gut....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nick</td>\n",
       "      <td>GB</td>\n",
       "      <td>Feb 16, 2024</td>\n",
       "      <td>1</td>\n",
       "      <td>morenutrition</td>\n",
       "      <td>Fraudsters - Bounty Nutrition…I ordered 1 prod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Julie Lutama</td>\n",
       "      <td>DE</td>\n",
       "      <td>A day ago</td>\n",
       "      <td>5</td>\n",
       "      <td>morenutrition</td>\n",
       "      <td>Tolle WebsiteTolle Website, super Produkte. Da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Kirsten Sinnecker</td>\n",
       "      <td>DE</td>\n",
       "      <td>Apr 14, 2024</td>\n",
       "      <td>5</td>\n",
       "      <td>morenutrition</td>\n",
       "      <td>Absolut tolle Produkt Absolut tolle Produkte m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Samira Schröter</td>\n",
       "      <td>DE</td>\n",
       "      <td>3 days ago</td>\n",
       "      <td>5</td>\n",
       "      <td>morenutrition</td>\n",
       "      <td>Alles topAlles top! Super lecker!Date of exper...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575</th>\n",
       "      <td>ninjamichelle li</td>\n",
       "      <td>CH</td>\n",
       "      <td>Updated Apr 27, 2022</td>\n",
       "      <td>2</td>\n",
       "      <td>morenutrition</td>\n",
       "      <td>Never received orderOrdered and paid (!!!) ove...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>576</th>\n",
       "      <td>Ailin Ngjela</td>\n",
       "      <td>AL</td>\n",
       "      <td>Feb 28, 2022</td>\n",
       "      <td>5</td>\n",
       "      <td>morenutrition</td>\n",
       "      <td>Tasty and healthy productsVery tasty and healt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577</th>\n",
       "      <td>Thea B.</td>\n",
       "      <td>DE</td>\n",
       "      <td>Jan 30, 2022</td>\n",
       "      <td>5</td>\n",
       "      <td>morenutrition</td>\n",
       "      <td>Vegan chunky Flavour Lemon Cheescake. YummyEin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578</th>\n",
       "      <td>Jüüü</td>\n",
       "      <td>DE</td>\n",
       "      <td>Jan 28, 2022</td>\n",
       "      <td>5</td>\n",
       "      <td>morenutrition</td>\n",
       "      <td>In love with Chunky FlavourOk ich gebs zu, ich...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>Momo Jar</td>\n",
       "      <td>DE</td>\n",
       "      <td>Jan 8, 2022</td>\n",
       "      <td>5</td>\n",
       "      <td>morenutrition</td>\n",
       "      <td>Echt gutEcht gut ! Nice !Date of experience: J...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>580 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Username Location                  Date Rating  \\\n",
       "0    Der auf die Bestellung wartet...       DE          Apr 21, 2024      3   \n",
       "1                                Nick       GB          Feb 16, 2024      1   \n",
       "2                        Julie Lutama       DE             A day ago      5   \n",
       "3                   Kirsten Sinnecker       DE          Apr 14, 2024      5   \n",
       "4                     Samira Schröter       DE            3 days ago      5   \n",
       "..                                ...      ...                   ...    ...   \n",
       "575                  ninjamichelle li       CH  Updated Apr 27, 2022      2   \n",
       "576                      Ailin Ngjela       AL          Feb 28, 2022      5   \n",
       "577                           Thea B.       DE          Jan 30, 2022      5   \n",
       "578                              Jüüü       DE          Jan 28, 2022      5   \n",
       "579                          Momo Jar       DE           Jan 8, 2022      5   \n",
       "\n",
       "           Company                                             Review  \n",
       "0    morenutrition  Wolf of WallstreetProdukte teilweise sehr gut....  \n",
       "1    morenutrition  Fraudsters - Bounty Nutrition…I ordered 1 prod...  \n",
       "2    morenutrition  Tolle WebsiteTolle Website, super Produkte. Da...  \n",
       "3    morenutrition  Absolut tolle Produkt Absolut tolle Produkte m...  \n",
       "4    morenutrition  Alles topAlles top! Super lecker!Date of exper...  \n",
       "..             ...                                                ...  \n",
       "575  morenutrition  Never received orderOrdered and paid (!!!) ove...  \n",
       "576  morenutrition  Tasty and healthy productsVery tasty and healt...  \n",
       "577  morenutrition  Vegan chunky Flavour Lemon Cheescake. YummyEin...  \n",
       "578  morenutrition  In love with Chunky FlavourOk ich gebs zu, ich...  \n",
       "579  morenutrition  Echt gutEcht gut ! Nice !Date of experience: J...  \n",
       "\n",
       "[580 rows x 6 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraped data for morenutrition.de saved to D:\\NU\\Spring24\\Artificial Neural Networks\\Neural Project\\CSV\\morenutrition.de_reviews.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "save_directory = \"D:\\\\NU\\\\Spring24\\\\Artificial Neural Networks\\\\Neural Project\\\\CSV\"\n",
    "\n",
    "# Save the scraped data to a CSV file\n",
    "filename = os.path.join(save_directory, f\"{company}_reviews.csv\")\n",
    "review_data.to_csv(filename, index=False)\n",
    "print(f\"Scraped data for {company} saved to {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All CSV files have been concatenated into one big CSV file.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "# Path to the directory containing your CSV files\n",
    "directory = \"D:\\\\NU\\\\Spring24\\\\Artificial Neural Networks\\\\Neural Project\\\\Scraped_Datasets\"\n",
    "\n",
    "# Get a list of all CSV files in the directory\n",
    "csv_files = glob.glob(f\"{directory}/*.csv\")\n",
    "\n",
    "# List to store DataFrames\n",
    "dataframes = []\n",
    "\n",
    "# Iterate over each CSV file\n",
    "for file in csv_files:\n",
    "    # Read the CSV file into a DataFrame and append to the list\n",
    "    dataframes.append(pd.read_csv(file))\n",
    "\n",
    "# Concatenate all DataFrames into one big DataFrame\n",
    "CompanyReviews = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "# Write the big DataFrame to a new CSV file\n",
    "CompanyReviews.to_csv('CompanyReviews.csv', index=False)\n",
    "\n",
    "print(\"All CSV files have been concatenated into one big CSV file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Username</th>\n",
       "      <th>Location</th>\n",
       "      <th>Date</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Company</th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Unknown</td>\n",
       "      <td>GB</td>\n",
       "      <td>2 days agoInvited</td>\n",
       "      <td>5</td>\n",
       "      <td>gymshark</td>\n",
       "      <td>PerfectShipping was so fast, really good quali...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sorina Irmak</td>\n",
       "      <td>TR</td>\n",
       "      <td>Apr 24, 2024</td>\n",
       "      <td>4</td>\n",
       "      <td>gymshark</td>\n",
       "      <td>I was unable to apply my discount code… I was ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tamara Rockall</td>\n",
       "      <td>GB</td>\n",
       "      <td>6 days agoInvited</td>\n",
       "      <td>5</td>\n",
       "      <td>gymshark</td>\n",
       "      <td>Fantastic as alwaysFantastic as always. There ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lauren</td>\n",
       "      <td>GB</td>\n",
       "      <td>Apr 15, 2024Invited</td>\n",
       "      <td>5</td>\n",
       "      <td>gymshark</td>\n",
       "      <td>Quick delivery and high quality The website is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Malcolm Rait</td>\n",
       "      <td>GB</td>\n",
       "      <td>4 days agoInvited</td>\n",
       "      <td>5</td>\n",
       "      <td>gymshark</td>\n",
       "      <td>Quality gym clothing easy to purchase…Quality ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43083</th>\n",
       "      <td>Instagram innerpeace_queen</td>\n",
       "      <td>US</td>\n",
       "      <td>Feb 22, 2022Invited</td>\n",
       "      <td>5</td>\n",
       "      <td>shein</td>\n",
       "      <td>Great stuffGreat stuff, literally the best!Dat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43084</th>\n",
       "      <td>Christina</td>\n",
       "      <td>US</td>\n",
       "      <td>Feb 22, 2022Invited</td>\n",
       "      <td>5</td>\n",
       "      <td>shein</td>\n",
       "      <td>ADD TO CART!!!!Quick shipping and the workout ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43085</th>\n",
       "      <td>Audrey</td>\n",
       "      <td>US</td>\n",
       "      <td>Feb 22, 2022Invited</td>\n",
       "      <td>5</td>\n",
       "      <td>shein</td>\n",
       "      <td>All of my clothes were amazing!Date of experie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43086</th>\n",
       "      <td>Michaela</td>\n",
       "      <td>US</td>\n",
       "      <td>Feb 22, 2022Invited</td>\n",
       "      <td>5</td>\n",
       "      <td>shein</td>\n",
       "      <td>@mdot2shoti love sheinnnn y’all pants be off t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43087</th>\n",
       "      <td>Meybelli</td>\n",
       "      <td>US</td>\n",
       "      <td>Feb 22, 2022Invited</td>\n",
       "      <td>5</td>\n",
       "      <td>shein</td>\n",
       "      <td>Did a good jobDate of experience: February 22,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>43088 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Username Location                 Date  Rating  \\\n",
       "0                         Unknown       GB    2 days agoInvited       5   \n",
       "1                    Sorina Irmak       TR         Apr 24, 2024       4   \n",
       "2                  Tamara Rockall       GB    6 days agoInvited       5   \n",
       "3                          Lauren       GB  Apr 15, 2024Invited       5   \n",
       "4                    Malcolm Rait       GB    4 days agoInvited       5   \n",
       "...                           ...      ...                  ...     ...   \n",
       "43083  Instagram innerpeace_queen       US  Feb 22, 2022Invited       5   \n",
       "43084                   Christina       US  Feb 22, 2022Invited       5   \n",
       "43085                      Audrey       US  Feb 22, 2022Invited       5   \n",
       "43086                    Michaela       US  Feb 22, 2022Invited       5   \n",
       "43087                    Meybelli       US  Feb 22, 2022Invited       5   \n",
       "\n",
       "        Company                                             Review  \n",
       "0      gymshark  PerfectShipping was so fast, really good quali...  \n",
       "1      gymshark  I was unable to apply my discount code… I was ...  \n",
       "2      gymshark  Fantastic as alwaysFantastic as always. There ...  \n",
       "3      gymshark  Quick delivery and high quality The website is...  \n",
       "4      gymshark  Quality gym clothing easy to purchase…Quality ...  \n",
       "...         ...                                                ...  \n",
       "43083     shein  Great stuffGreat stuff, literally the best!Dat...  \n",
       "43084     shein  ADD TO CART!!!!Quick shipping and the workout ...  \n",
       "43085     shein  All of my clothes were amazing!Date of experie...  \n",
       "43086     shein  @mdot2shoti love sheinnnn y’all pants be off t...  \n",
       "43087     shein  Did a good jobDate of experience: February 22,...  \n",
       "\n",
       "[43088 rows x 6 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CompanyReviews"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
